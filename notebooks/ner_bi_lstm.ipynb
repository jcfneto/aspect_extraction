{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from numpy.random import seed\n",
    "from itertools import chain\n",
    "from tensorflow.keras import Model,Input\n",
    "from tensorflow.keras.layers import LSTM,Embedding,Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D,Bidirectional"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('ner.csv', encoding=\"latin1\", on_bad_lines='skip')\n",
    "data.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols_to_keep = ['sentence_idx', 'word', 'tag']\n",
    "data = data[cols_to_keep]\n",
    "data.head(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "words = list(set(data[\"word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "num_words = len(words)\n",
    "\n",
    "print(f\"Total number of unique words in dataset: {num_words}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tags = list(set(data[\"tag\"].values))\n",
    "num_tags = len(tags)\n",
    "print(\"List of tags: \" + ', '.join([tag for tag in tags]))\n",
    "print(f\"Total Number of tags {num_tags}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class GetSentence(object):\n",
    "    def __init__(self,data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        agg_func = lambda s:[(w, t) for w, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                    s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"sentence_idx\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "getter = GetSentence(data)\n",
    "sentence = getter.sentences\n",
    "sentence[10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_idx = {w : i + 1 for i ,w in enumerate(words)}\n",
    "tag_idx =  {t : i for i ,t in enumerate(tags)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_len = 50\n",
    "X = [[word_idx[w[0]] for w in s] for s in sentence]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding='post', value=num_words - 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = [[tag_idx[w[1]] for w in s] for s in sentence]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding='post', value=tag_idx['O'])\n",
    "y = [to_categorical(i, num_classes=num_tags) for i in  y]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(x_train), len(x_test), len(y_train), len(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_word = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=num_words, output_dim=max_len, input_length=max_len)(input_word)\n",
    "model = SpatialDropout1D(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(num_tags, activation='softmax'))(model)\n",
    "model = Model(input_word, out)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(x_train, np.array(y_train), batch_size=64, verbose=1, epochs=3, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Second test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import defaultdict\n",
    "from datasets import Dataset, DatasetDict\n",
    "from src import utils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from transformers import create_optimizer, AutoTokenizer, TFBertModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples: dict) -> Dataset:\n",
    "    \"\"\"Tokenize and align labels with subword tokens.\n",
    "\n",
    "    Args:\n",
    "        examples: Pre-token.\n",
    "\n",
    "    Returns:\n",
    "        Tokens with labels.\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['tokens'],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        max_length=100,\n",
    "        pad_to_max_length=True\n",
    "    )\n",
    "    all_labels = examples['aspect_tags']\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(utils.align_labels_with_tokens(labels, word_ids))\n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "class BiLSTM(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.bilstm = tf.keras.layers.Bidirectional(\n",
    "            tf.keras.layers.LSTM(units, return_sequences=True))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.bilstm(inputs)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lendo os dados\n",
    "data_ds = pd.read_csv('../datasets/processed/tv_stratified.csv')\n",
    "\n",
    "# mudando o formato das colunas\n",
    "for col in ('tokens', 'aspect_tags'):\n",
    "    data_ds[col] = data_ds[col].apply(literal_eval)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_chekpoint = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_chekpoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tag mapping\n",
    "id2label = {0: 'O', 1: 'B-ASP', 2: 'I-ASP'}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "label_names = ['O', 'B-ASP', 'I-ASP']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(data_ds[['tokens', 'aspect_tags']])\n",
    "data = data.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=data.column_names\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    'input_ids': tf.convert_to_tensor(data['input_ids'], dtype=tf.int32),\n",
    "    'attention_mask': tf.convert_to_tensor(data['attention_mask'], dtype=tf.int32),\n",
    "    'token_type_ids': tf.convert_to_tensor(data['token_type_ids'], dtype=tf.int32),\n",
    "}\n",
    "labels = tf.convert_to_tensor(data['labels'], dtype=tf.int32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the BERT model and tokenizer\n",
    "bert_model = TFBertModel.from_pretrained(model_chekpoint)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# camadas\n",
    "inputs = [layers.Input(shape=(None,), dtype=tf.int32, name=name) for name in ('input_ids', 'attention_mask', 'token_type_ids')]\n",
    "embedding = bert_model(inputs)[0]\n",
    "bilstm = BiLSTM(units=32)(embedding)\n",
    "outputs = layers.TimeDistributed(layers.Dense(units=3, activation='softmax'))(bilstm)\n",
    "model = keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a custom loss function that ignores padding tokens\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# Compile the model with the custom loss function\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=custom_loss,\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train_on_batch(input_data, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
