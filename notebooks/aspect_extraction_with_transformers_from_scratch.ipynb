{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from datasets import Dataset\n",
    "from src import utils\n",
    "from src.conlleval import evaluate\n",
    "from src.models import AEModelConfig, AEModel, CustomNonPaddingTokenLoss\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# lendo os dados\n",
    "data_df = pd.read_csv('../datasets/processed/tv_stratified.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# mudando o formato das colunas\n",
    "for col in ('tokens', 'aspect_tags'):\n",
    "    data_df[col] = data_df[col].apply(literal_eval)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# transformando em o dataframe em Dataset\n",
    "cols_to_keep = ['tokens', 'aspect_tags']\n",
    "data_ds = Dataset.from_pandas(data_df[cols_to_keep])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# separando em treino, teste e validacÃ£o\n",
    "data_ds = utils.train_test_val_split(data_ds, test_size=0.1, val_size=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.mkdir('data')\n",
    "utils.save_data_to_file('./data/tv_train.txt', data_ds['train'])\n",
    "utils.save_data_to_file('./data/tv_validation.txt', data_ds['validation'])\n",
    "utils.save_data_to_file('./data/tv_test.txt', data_ds['test'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '[PAD]', 1: 'O', 2: 'B-ASP', 3: 'I-ASP'}\n"
     ]
    }
   ],
   "source": [
    "mapping = utils.make_tag_lookup_table()\n",
    "print(mapping)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3158\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sum(data_ds['train']['tokens'], [])\n",
    "all_tokens_array = np.array(all_tokens)\n",
    "\n",
    "counter = Counter(all_tokens_array)\n",
    "print(len(counter))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "num_tags = len(mapping)\n",
    "vocab_size = 3_100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "vocabulary = [token for token, count in counter.most_common(vocab_size - 2)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 09:03:55.924166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:55.955377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:55.955575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:55.956296: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 09:03:55.956871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:55.957037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:55.957182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:56.309986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:56.310182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:56.310371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-06 09:03:56.310511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4023 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:06:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "lookup_layer = layers.StringLookup(vocabulary=vocabulary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_data = tf.data.TextLineDataset(\"./data/tv_train.txt\")\n",
    "val_data = tf.data.TextLineDataset(\"./data/tv_validation.txt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def convert_to_ids(tokens):\n",
    "    return lookup_layer(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = (\n",
    "    train_data.map(utils.map_record_to_training_data)\n",
    "    .map(lambda x, y: (convert_to_ids(x), y))\n",
    "    .padded_batch(batch_size)\n",
    ")\n",
    "val_dataset = (\n",
    "    val_data.map(utils.map_record_to_training_data)\n",
    "    .map(lambda x, y: (convert_to_ids(x), y))\n",
    "    .padded_batch(batch_size)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "ae_config = AEModelConfig(num_tags, vocab_size, embed_dim=32, num_heads=4, ff_dim=64)\n",
    "ae_model = AEModel(ae_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ferreira/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 16ms/step - loss: 0.4625\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.2465\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1560\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1315\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1205\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1136\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.1078\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1034\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0993\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0946\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0900\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0856\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0808\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0769\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0751\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0786\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0715\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0653\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0615\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0626\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0772\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0756\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0659\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0576\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0527\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0505\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0490\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0474\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0456\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0434\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7fbcf43838e0>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_model.compile(optimizer='adam', loss=CustomNonPaddingTokenLoss())\n",
    "ae_model.fit(train_dataset, epochs=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def tokenize_and_convert_to_ids(text):\n",
    "    tokens = text.split()\n",
    "    return convert_to_ids(tokens)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def calculate_metrics(dataset):\n",
    "    all_true_tag_ids, all_predicted_tag_ids = [], []\n",
    "\n",
    "    for x, y in dataset:\n",
    "        output = ae_model.predict(x)\n",
    "        predictions = np.argmax(output, axis=-1)\n",
    "        predictions = np.reshape(predictions, [-1])\n",
    "\n",
    "        true_tag_ids = np.reshape(y, [-1])\n",
    "\n",
    "        mask = (true_tag_ids > 0) & (predictions > 0)\n",
    "        true_tag_ids = true_tag_ids[mask]\n",
    "        predicted_tag_ids = predictions[mask]\n",
    "\n",
    "        all_true_tag_ids.append(true_tag_ids)\n",
    "        all_predicted_tag_ids.append(predicted_tag_ids)\n",
    "\n",
    "    all_true_tag_ids = np.concatenate(all_true_tag_ids)\n",
    "    all_predicted_tag_ids = np.concatenate(all_predicted_tag_ids)\n",
    "\n",
    "    predicted_tags = [mapping[tag] for tag in all_predicted_tag_ids]\n",
    "    real_tags = [mapping[tag] for tag in all_true_tag_ids]\n",
    "\n",
    "    evaluate(real_tags, predicted_tags)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "processed 3132 tokens with 216 phrases; found: 274 phrases; correct: 151.\n",
      "accuracy:  63.14%; (non-O)\n",
      "accuracy:  93.52%; precision:  55.11%; recall:  69.91%; FB1:  61.63\n",
      "              ASP: precision:  55.11%; recall:  69.91%; FB1:  61.63  274\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(val_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
